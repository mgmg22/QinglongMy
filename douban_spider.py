#!/bin/env python3
# -*- coding: utf-8 -*
# """
# cron: 5 9 * * * weibo_summary.py
# new Env('è±†ç“£ç§Ÿæˆ¿');
# """
from bs4 import BeautifulSoup
import requests
import sendNotify

summary_list = []

# # æŽ’é™¤é¡¹
user_black_list = [
    "æ¨æµ¦ç§Ÿæˆ¿",
    "äº”è§’åœºç§Ÿèµ",
    "äº”è§’åœºç§Ÿæˆ¿",
    "PiNa@ä¸Šæµ·ç›´ç§Ÿ",
    "äº”è§’åœºé™„è¿‘",
    "æ²ªä¸Šèœ—å±…å°è±†è±†",
    "ðŸƒ ðŸ‡¨ðŸ‡³",
    "è±†å‹280014083",
    "ç“œç“œä¸€å·çš„å¢¨è¿¹",
    "é»„æµ¦åŒºç§Ÿæˆ¿",
    "å¨œå¨œå°å¤­",
    "è‡ªç”±å¥”æ”¾",
    "æ±Ÿæ¹–ä¸è‰¯äºº",
    "åŽå¤ä¸œè·¯",
    "æ¸…é£Žç§€é›…",
    "çµæ„Ÿä¹‹åˆƒ",
    "ç»™ä½ ä¿©çªçª",
    "ç®€å•ç‚¹",
    "å¿§ä¼¤çš„æ—‹å¾‹",
    "C",
    "ä¹å¤´å¥ˆå­",
    "æŽå¥½é—²ã€‚",
    "å°å¼ è¦å¢žè‚Œ",
    "è™šä¼ªçš„ä¸–ç•Œ",
    "æ£®å¥³ä¸Žé¹¿æž—",
    "æå­",
    "æ‚²ä¼¤çš„è¯—ç¯‡",
    "ç›¸æ€æˆæ®‡",
    "å®‰é™çš„ç­‰å¾…",
    "-Joker",
    "è±†å‹279607317",
    "è±†å‹279607320",
    "è±†å‹270169870",
    "è±†å‹279607122",
    "ç¥ˆé¹¤",
    "å¯æ€œå¼.æš§æƒ…",
    "å¦‚èŠ±ç¾Žçœ·",
    "è±†å‹279434723",
    "è±†å‹279434727",
    "ä»Žæ‚²ä¼¤ä¸­æŠ½ç¦»",
]


def filter_tr(tr):
    # print("-----")
    title = tr.select('td.title')
    if not title:
        return False
    if "ç½®é¡¶" in str(title):
        return False
    user = tr.select('td:nth-child(2)')[0].find('a').get_text()
    if user in user_black_list:
        return False
    text = title[0].find('a')['title']
    # æŽ’é™¤é¡¹
    blackList = [
        "å¥³ç”Ÿ", "æˆ¿æº", "å…¬ç§¯é‡‘", "å±…ä½è¯", "é’¥åŒ™", "åˆ«å¢…",
        "é—µè¡Œ", "å¾å®¶æ±‡", "æ¼•æ²³æ³¾", "æ¼•å®", "ä¸ƒå®", "è™¹æ¡¥",
        "æ¾æ±Ÿ", "ä¹äº­", "èŽ˜åº„",
        "é’æµ¦", "æ³—æ³¾",
        "å®å±±", "ä¸Šæµ·å¤§å­¦", "å‘¼å…°", "å½­æµ¦",
        "å˜‰å®š",
        "æµ¦ä¸œ", "é™†å®¶å˜´", "å¼ æ±Ÿ", "ä¸–çºªå…¬å›­", "é¾™é˜³è·¯", "èŠ±æœ¨",
        "é™å®‰",
        "æ™®é™€",
        "ä¸‰æž—", "æ¨æ€", "ä¸–åš",
    ]
    if any(sub in text for sub in blackList):
        return False
    time = tr.select('td.time')[0].text
    href = title[0].find('a')['href']
    print(text + '\t\t' + time + '\t\t' + user + '\t\t' + href)
    item = {
        'user': user,
        'title': text,
        'href': href,
        'time': time,
    }
    summary_list.append(item)


def get_top_summary(start):
    # url = 'https://www.douban.com/group/wujiaochang/discussion?start='+ str(start)
    # url = 'https://www.douban.com/group/383972/discussion?start='+ str(start)
    url = 'https://www.douban.com/group/shanghaizufang/discussion?start=' + str(start)
    headers = {
        'accept': "*/*",
        'user-agent': "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    }
    data = requests.get(url, headers=headers)
    data.encoding = 'utf-8'
    soup = BeautifulSoup(data.text, 'html.parser')
    tr_elements = soup.select('#content > div > div.article > div:nth-child(2) > table> tr')
    for tr in tr_elements:
        filter_tr(tr)
    if len(summary_list) <= 20:
        print("-----")
        get_top_summary(start + 25)


if __name__ == '__main__':
    get_top_summary(0)
    # notify_markdown()
